name: OushuDB RPM

on: [push, pull_request]

jobs:
  Cache-Binary:
    runs-on: ubuntu-latest
    steps:
 
    - name: Cache HDFS tar
      id: cache-hdfs-tar
      uses: actions/cache@v3
      with:
        key: hadoop-3.3.0
        path: hadoop-3.3.0.tar.gz

    - name: Download HDFS tar
      if: ${{ steps.cache-hdfs-tar.outputs.cache-hit != 'true' }}
      run: wget -nv https://archive.apache.org/dist/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz

  Install-and-Test:
    needs: Cache-Binary
    defaults:
      run:
        shell: bash -e -l {0}

    strategy:
      fail-fast: false
      matrix:
        # platform: []ubuntu-20.04]
        version:
          # missing RPM
          # - 3.0.1.0
          # - 3.1.2.0
          # - 3.2.0.0
          # - 3.3.0.0
          # - 3.3.0.0
          # - 3.4.1.0

          # severe performance issue on ClickBench
          - 4.0.5.0
          # - 4.0.7.0
          # - 4.2.0.0
          - 4.3.0.0
          - 4.4.0.0

          # acceptable
          - 4.5.2.0
          - 4.6.1.0
          - 4.7.0.0
          - 4.8.0.2
          - 4.9.4.0

          - 5.0.0.0
        benchmark:
          - tpc-h
          - clickbench

    runs-on: ubuntu-20.04 # ${{ matrix.platform }}

    steps:

    - uses: actions/checkout@v2

    - name: initilize OS
      run: |
        case $(uname -s) in
          Darwin) .github/workflows/scripts/init_macos.sh ;;
          Linux)  .github/workflows/scripts/init_linux.sh ;;
        esac
        ./install.sh

    - name: check yzy script
      run: |
        # command -v oushudb # DEBUG yzy install succeed
        command -v psql
        env

    - name: Cache HDFS tar
      id: cache-hdfs-tar
      uses: actions/cache@v3
      with:
        key: hadoop-3.3.0
        path: hadoop-3.3.0.tar.gz

    - if: ${{ steps.cache-hdfs-tar.outputs.cache-hit != 'true' }}
      name: Download HDFS tar
      run: wget -nv https://archive.apache.org/dist/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz

    - name: install HDFS
      run: |
        sudo install -o $USER -d /usr/local/hadoop-3.3.0
        sudo ln -snf hadoop-3.3.0 /usr/local/hadoop
        sudo tee /usr/local/bin/hdfs <<<'exec /usr/local/hadoop/bin/hdfs $@'
        sudo chmod a+x /usr/local/bin/hdfs
        tar xf hadoop-3.3.0.tar.gz -C /usr/local/

    - name: Detect HAWQ RPM
      run: |
        export RPM_VER=${{ matrix.version }}
        RPM_REPO_PREFIX_LIST=(http://yum.oushu.com/oushurepo/yumrepo/release/oushu-database/centos6/
                              http://yum.oushu.com/oushurepo/yumrepo/release/oushu-database/centos7/
                              http://139.217.102.138:12000/oushurepo/yumrepo/test/oushu-database/centos6/
                             )

        # check out the RPM URL
        for RPM_REPO_PREFIX in "${RPM_REPO_PREFIX_LIST[@]}"; do
          export RPM_REPO=$RPM_REPO_PREFIX/$RPM_VER/release/
          export RPM_NAME=$(curl -s $RPM_REPO/ | sed -E -n 's/.*href="((hawq|oushudb)-[0-9][^"]*)".*/\1/p')
          if test -n "$RPM_NAME"; then
            break;
          fi
        done

        test -n "$RPM_NAME"
        echo "RPM_REPO=${RPM_REPO}" >> $GITHUB_ENV
        echo "RPM_NAME=${RPM_NAME}" >> $GITHUB_ENV

        sudo chmod a+rw /usr/local # XXX: ensure for cache export

    - name: Cache HAWQ RPM
      id: cache-hawq-rpm
      uses: actions/cache@v3
      with:
        key: ${{ env.RPM_NAME }}
        # path: ${{ env.RPM_NAME }}
        path: /usr/local/oushudb-${{ matrix.version }}

    - name: Download HAWQ RPM
      if: ${{ steps.cache-hawq-rpm.outputs.cache-hit != 'true' }}
      run: |
        wget $RPM_REPO/$RPM_NAME
        sudo rpm -ivh --nodeps $RPM_NAME

    - name: install HAWQ
      run: |
        sudo ln -snf oushudb-${{ matrix.version }} /usr/local/hawq
        sudo ln -snf oushudb-${{ matrix.version }} /usr/local/oushudb
        if [[ -d /usr/local/oushu/oushudb ]]; then # in case of 5.0
          sudo ln -snf /usr/local/oushu/oushudb /usr/local/hawq
          sudo ln -snf /usr/local/oushu/oushudb /usr/local/oushudb
          sudo ln -snf /usr/local/hawq/oushudb_path.sh /usr/local/hawq/greenplum_path.sh
          sudo chown -R $USER:$USER /usr/local/oushu/
          echo 'export GPHOME=$OUSHUDB_HOME' >>/usr/local/hawq/oushudb_path.sh
        fi
        sudo chown -R $USER:$USER /usr/local/oushudb/

        ls -ltr /usr/local
        source /usr/local/oushudb/greenplum_path.sh
        postgres -V
        echo "PGDATABASE=postgres" >> $GITHUB_ENV
        echo "PGHOST=localhost" >> $GITHUB_ENV

    - name: initilize HDFS
      run: |
        export HADOOP_HOME=/usr/local/hadoop/
        .github/workflows/scripts/init_hdfs.sh

    - name: initilize HAWQ
      run: |
        source /usr/local/oushudb/greenplum_path.sh
        .github/workflows/scripts/init_oushudb.sh
        psql -c 'select version();'
        psql -d postgres -c 'create database hawq_feature_test_db;'

    - name: test HAWQ TPC-H schema
      if: ${{ matrix.benchmark == 'tpc-h' }}
      run: |
        source /usr/local/oushudb/greenplum_path.sh
        mkdir tpc-h/
        psql -d postgres -f sql/tpc-h-schema.sql 
        if hawq version | grep 'version 4\.[0-5]'; then
          psql -d postgres -f sql/tpc-h.ext.exec.dbgen.2.6.sql
        else
          psql -d postgres -f sql/tpc-h-ext-exec-dbgen.sql
        fi
        psql -d postgres -f sql/tpc-h.analyze.sql

    - name: test HAWQ TPC-H load
      if: ${{ matrix.benchmark == 'tpc-h' }}
      run: |
        source /usr/local/oushudb/greenplum_path.sh
        psql -d postgres -af sql/init_tpchschema.load.sql

    - name: test HAWQ TPC-H analyze
      if: ${{ matrix.benchmark == 'tpc-h' }}
      run: psql -af sql/tpc-h.analyze.sql

    - name: test HAWQ TPC-H execute
      if: ${{ matrix.benchmark == 'tpc-h' }}
      run: |
        source /usr/local/oushudb/greenplum_path.sh
        psql -d postgres -v ON_ERROR_STOP=1 -af sql/tpc-h.sql | tee tpc-h/$RPM_NAME.out |
          sed -n 's/Time://p' | awk '{print NR, $0}'

    - name: Cache ClickBench tar
      if: ${{ matrix.benchmark == 'clickbench' }}
      id: cache-clickbench-tar
      uses: actions/cache@v3
      with:
        key: clickbench-10M
        path: hits.tsv

    - name: Download ClickBench tar
      if: ${{ steps.cache-clickbench-tar.outputs.cache-hit != 'true' }}
      run: |
        curl https://datasets.clickhouse.com/hits_compatible/hits.tsv.gz |
          gunzip  | head -n 10000000 > hits.tsv # 10M tuple

    - name: test ClickBench schema
      if: ${{ matrix.benchmark == 'clickbench' }}
      run: |
        source /usr/local/oushudb/greenplum_path.sh
        nohup gpfdist -l gpfdist.log &
        mkdir clickbench/
        psql -f sql/clickbench/create.sql
        psql -c "insert into hits select * from hits_ext order by CounterID, EventDate, UserID, EventTime, WatchID;"
        psql -c "select pg_size_pretty(pg_relation_size('hits'));"

    - name: test ClickBench execute
      if: ${{ matrix.benchmark == 'clickbench' }}
      run: |
        source /usr/local/oushudb/greenplum_path.sh
        psql -c 'ALTER DATABASE postgres set new_executor_enable_partitioned_hashagg to off;'
        psql -c 'ALTER DATABASE postgres set standard_conforming_strings to on;'
        psql -c 'ALTER DATABASE postgres set gp_eager_one_phase_agg to on;'
        
        # psql -f <(echo '\timing on'; cat sql/clickbench/queries.sql;) |
        #  tee clickbench/$RPM_NAME.out |
        #  sed -n 's/Time://p' | awk '{print NR, $0}'
        cd sql/clickbench
        ./run.sh > $GITHUB_WORKSPACE/clickbench/$RPM_NAME.out

    - name: archive results
      uses: actions/upload-artifact@v2
      with:
        name: results
        path: |
          tpc-h/${{ env.RPM_NAME }}.out
          clickbench/${{ env.RPM_NAME }}.out

  analyze:
    needs: [Install-and-Test]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    
    - name: Download all workflow run artifacts
      uses: actions/download-artifact@v3

    - name: html
      run: |
        ls results/
        mkdir ~/dev/
        git clone https://github.com/ClickHouse/ClickBench/ ~/dev/ClickBench

        cd $GITHUB_WORKSPACE/results/tpc-h
        $GITHUB_WORKSPACE/sql/clickbench/generate-result-html.sh
        cp ~/dev/ClickBench/index.html ./

        cd $GITHUB_WORKSPACE/results/clickbench
        $GITHUB_WORKSPACE/sql/clickbench/generate-result-html.sh
        cp ~/dev/ClickBench/index.html ./

    - name: archive results
      uses: actions/upload-artifact@v2
      with:
        name: results
        path: results